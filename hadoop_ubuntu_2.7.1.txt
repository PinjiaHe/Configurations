From: https://www.youtube.com/watch?v=YY8QL25KCOg

Step by step hadoop 2.7.1 installation in ubuntu 14.04(single node cluster)

Hadoop pre-requisites

a) sudo apt-get update

b) sudo apt-get install default-jdk

c) java -version

d) sudo addgroup hadoop

e) sudo adduser --ingroup hadoop hduser
 
f) sudo adduser hduser sudo

g) sudo apt-get install openssh-server

h) su hduser

i) ssh-keygen -t rsa -P ""

j) cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys


Installing Hadoop

1) wget http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz

2) tar xvzf hadoop-2.7.1.tar.gz

3) sudo mv hadoop-2.7.1 /usr/local/hadoop

4) sudo chown -R hduser:hadoop /usr/local/hadoop


Configuring hadoop files

1) BASHRC

sudo nano ~/.bashrc

#append the code below to the end of the file and save it

export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"

#type the command below afterward

source ~/.bashrc

#then go to the hadoop-env.sh file

sudo nano /usr/local/hadoop/etc/hadoop/hadoop-env.sh

#look for the export JAVA_HOME and replace the part after the = with the path to java(this my path below)

export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64

2) Configuration file : core-site.xml

sudo nano /usr/local/hadoop/etc/hadoop/core-site.xml

<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>

3)Configuration file : hdfs-site.xml

sudo nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml

<property>
      <name>dfs.replication</name>
      <value>1</value>
 </property>
 <property>
      <name>dfs.namenode.name.dir</name>
      <value>file:/usr/local/hadoop_tmp/hdfs/namenode</value>
 </property>
 <property>
      <name>dfs.datanode.data.dir</name>
      <value>file:/usr/local/hadoop_tmp/hdfs/datanode</value>
 </property>

4)Configuration file : yarn-site.xml

sudo nano /usr/local/hadoop/etc/hadoop/yarn-site.xml

<property>
      <name>yarn.nodemadnager.aux-services</name>
      <value>mapreduce_shuffle</value>
</property>
<property>
      <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
      <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>

5) Configuration file : mapred-site.xml

cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.template  /usr/local/hadoop/etc/hadoop/mapred-site.xml

sudo nano /usr/local/hadoop/etc/hadoop/mapred-site.xml

<property>
      <name>mapreduce.framework.name</name>
      <value>yarn</value>
</property>

Creating hdfs directory to store hdfs files

5) sudo mkdir -p /usr/local/hadoop_tmp

6) sudo mkdir -p /usr/local/hadoop_tmp/hdfs/namenode

7) sudo mkdir -p /usr/local/hadoop_tmp/hdfs/datanode

8) sudo chown -R hduser /usr/local/hadoop_tmp


hdfs namenode -format

start-dfs.sh
start-yarn.sh
jps